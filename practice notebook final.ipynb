{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def clean_and_preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase the text\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    stop_words = set(stopwords.words('english'))  # Get English stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    cleaned_text = ' '.join(tokens)  # Join tokens back into text\n",
    "    cleaned_text\n",
    "    return cleaned_text\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"sampled.csv\")\n",
    "\n",
    "# Clean and preprocess the 'TITLE' and 'SECTION_TEXT' columns\n",
    "df['TITLE'] = df['TITLE'].apply(clean_and_preprocess_text)\n",
    "df['SECTION_TEXT'] = df['SECTION_TEXT'].apply(clean_and_preprocess_text)\n",
    "\n",
    "# Concatenate 'TITLE' and 'SECTION_TEXT' columns to create 'ARTICLE_TEXT'\n",
    "df['ARTICLE_TEXT'] = df['TITLE'] + \" \" + df['SECTION_TEXT']\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv(\"cleaned_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# Read the cleaned data\n",
    "df_cleaned = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Function to calculate term frequency\n",
    "def calculate_term_frequency(text):\n",
    "    word_counts = Counter(text.split())\n",
    "    return word_counts\n",
    "\n",
    "# Calculate term frequency for each document\n",
    "df_cleaned['TERM_FREQUENCY'] = df_cleaned['ARTICLE_TEXT'].apply(calculate_term_frequency)\n",
    "\n",
    "# Function to calculate document frequency\n",
    "def calculate_document_frequency(df):\n",
    "    document_frequency = Counter()\n",
    "    for index, row in df.iterrows():\n",
    "        document_frequency.update(row['TERM_FREQUENCY'].keys())\n",
    "    return document_frequency\n",
    "\n",
    "# Calculate document frequency\n",
    "document_frequency = calculate_document_frequency(df_cleaned)\n",
    "\n",
    "# Function to calculate inverse document frequency\n",
    "def calculate_inverse_document_frequency(total_documents, df):\n",
    "    inverse_document_frequency = {}\n",
    "    for term, freq in df.items():\n",
    "        idf = 1 + log(total_documents / (freq + 1))\n",
    "        inverse_document_frequency[term] = idf\n",
    "    return inverse_document_frequency\n",
    "\n",
    "# Calculate total number of documents\n",
    "total_documents = len(df_cleaned)\n",
    "# Calculate inverse document frequency\n",
    "inverse_document_frequency = calculate_inverse_document_frequency(total_documents, document_frequency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 0, Relevance Score: 0.0, Content: delavan illinois delavan founded group settler new england city derives name edward c delavan temperance advocate albany new york post office operation delavan since 1840\n",
      "Document ID: 1, Relevance Score: 0.0, Content: silver creek township lake county minnesota silver creek township township lake county minnesota united state population 1178 2000 census minnesota state highway 61 serf main route township silver creek township organized 1905\n",
      "Document ID: 2, Relevance Score: 0.0, Content: holbrook new york \n",
      "Document ID: 3, Relevance Score: 0.0, Content: violent femmes album violent femmes adobe flash radio3net streamed copy licensed\n",
      "Document ID: 4, Relevance Score: 0.0, Content: kragerø town kragerø established municipality 1 january 1838 see formannskapsdistrikt day sailing ship kragerø one norway largest port city rural municipality sannidal skåtøy merged municipality kragerø 1 january 1960 municipality includes 495 island islet skerries along 4000 leisure house also 190 freshwater lake municipality 1694 murder 17 august 1694 christian hansen ernst killed presentday knivstikkersmauet knife stabber alley employee postal service former servant ulrik fredrik gyldenløve one african time living norway whose identity known\n",
      "Document ID: 5, Relevance Score: 0.0, Content: brainstem adult human brainstem emerges two three primary vesicle formed neural tube mesencephalon second three primary vesicle differentiate secondary vesicle become midbrain third primary vesicle rhombencephalon hindbrain differentiate two secondary vesicle metencephalon myelencephalon metencephalon become cerebellum pons caudal myelencephalon become medulla\n",
      "Document ID: 6, Relevance Score: 0.0, Content: julian byng 1st viscount byng vimy byng born family seat wrotham park hertfordshire seventh son 13th youngest child earl strafford due size family ran relatively frugal household harriet elizabeth cavendish daughter lord chesham age 17 byng enrolled eton college although enter sixth form eton byng first received nickname bungo—to distinguish elder brother byngo bango—but time college undistinguished received poor report indicative attitude towards academic traded latin grammar book brother lionels best trouser hawker pair ferret pineapple byng later claimed school worst scug colloquial term undistinguished boy\n",
      "Document ID: 7, Relevance Score: 0.0, Content: gina lynn avn gina lynn hurt motorcycle stunt dan miller august 29 2005 gina lynn babepedia\n",
      "Document ID: 8, Relevance Score: 0.0, Content: dorpat voivodeship 26 august 1625 tartu capitulated sweden 1627–1634 kasper doenhoff caspar dönhoff c 1588–1645 1634–1640 gothard jan tyzenhauz died 1640 1641–1651 andrzej leszczyński c 1606–1651 1651–1651 enoch kolenda 1651–1654 teodor denhoff died 1654 pl 1654–1654 zygmunt opacki died 1654 1654–1658 olbracht opacki c 1621–1680 –1657 aleksander ludwik wolff 1657–1658 zygmunt wybranowski 1658–1660 przecław paweł leszczyński 1605–1670 1670–1676 samuel leszczyński 1637–1676\n",
      "Document ID: 9, Relevance Score: 0.0, Content: oberonclass submarine helm station aboard western australian maritime museum 2006 least fourteen oberons confirmed survived form seven preserved converted museum vessel tourist attraction two partially preserved monument another five awaiting conversion museum work otherwise awaiting disposal two exroyal navy submarine preserved uk one remains hm onyx moved barrowinfurness museum birkenhead merseyside closed later towed gareloch scotland broken scrap 2014 failed attempt turn museum boat located chatham harboured sassnitz germany island rügen visited another two british oberons transferred canada noncommissioned training vessel spare part british submarine disposed australia six oberons preserved display either completely partially located western australian maritime museum fremantle located australian national maritime museum darling harbour sydney fin outer hull stern section preserved land holbrook new south wale located crib point westernport bay victoria awaiting conversion museum vessel since 2002 lack funding cooperation local state government mean volunteer group hoping preserve otama attempted sell submarine ebay avail fin stand permanent memorial garden island western australia fin stand permanent memorial rockingham naval memorial park western australia three oberonclass submarine laid halifax harbour 2005 announced four surviving canadian submarine minus osiris scrapped 1992 stripped part sold scrapping deteriorated beyond point use purchased c4 plus tax site historique maritime de la pointeaupère use museum vessel towed halifax pointeaupère quebec july 2008 july 2011 olympus towed scrapyard port maitland ontario delivered scrapyard august 2011 preserved part elgin military museum moved port burwell ontario november 2012 become focal point new museum naval history ojibwa opened public tour july 2013 one brazilian oberons tonelero sank docked navy yard praça mauá rio de janeiro 24 december 2000 surviving brazilian oberon riachuelo converted museum brazilian navy cultural center espaço cultural da marinha brasileira rio de janeiro chilean navy sold obrien city valdivia converted first submarine museum chile submarine modified asenav shipyard better access general public moored callecalle river cross city successor oberon class briefly succeeded rn service upholderclass submarine upholderclass submarine later upgraded sold canada service royal canadian navy refit victoria class replacing oberons australian oberons replaced six two chilean oberons replaced ohiggins carrera brazilian oberons replaced type 209 submarine\n",
      "Document ID: 10, Relevance Score: 0.0, Content: jessye norman throughout career norman spent much time giving recital concert addition operatic norman given regular recital encompassing classical german repertory well contemporary masterpiece schoenberg gurrelieder french modern invariably performed original tongue combination scholarship artistry contributed consistently successful career one versatile concert operatic singer time often cited innovative programming fervent advocacy contemporary music earned recognition one onceinageneration singer ’ simply following footstep others staking niche history singing norman premiered song cycle womanlifesong composer judith weir work commissioned carnegie hall text toni morrison maya angelou clarissa pinkola estés performed selection sacred music duke ellington recorded jazz album jessye norman sings michel legrand soprano colead vangelis project mythodea moscow norman performed song mussorgsky original russian project included 1984 album song heart contains number film musical comedy 1990 performance american spiritual soprano kathleen battle carnegie hall\n",
      "Document ID: 11, Relevance Score: 0.0, Content: khmelnytskyi ukraine khmelnytskyi railway station khmelnytskyi infrastructure transportation connection moscow prague bratislava warsaw budapest belgrade major ukrainian city distance khmelnytskyi kiev railway estimated highway estimated highway kievlviv odessalviv chernivtsikiev pas khmelnytskyi city served khmelnytskyi ruzhychna airport khmelnytskyis airport concrete runway airport check point crossing state border ukraine\n",
      "Document ID: 12, Relevance Score: 0.0, Content: pavel kubina pavel kubina born april 15 1977 czech former ice hockey defenceman played national hockey league nhl tampa bay lightning toronto maple leaf atlanta thrasher philadelphia flyer\n",
      "Document ID: 13, Relevance Score: 0.0, Content: internal ballistics prior mid1800s development electronics necessary mathematics see euler material science fully understand pressure vessel design internal ballistics lot detailed objective information barrel action would simply built strong enough survive known overload proof test muzzle velocity change could surmised distance projectile traveled 1800s test barrel began instrumented hole drilled barrel crusher gauge using copper pellet attached gun fired pressure measured indirectly much copper pellet deformed measurement indicated maximum pressure reached point barrel 1960s piezoelectric strain gauge used allow instantaneous pressure measured need pressure port drilled barrel recently using advanced telemetry accelerationhardened sensor instrumented projectile developed could measure pressure base projectile acceleration\n",
      "Document ID: 14, Relevance Score: 0.0, Content: swimming 2004 summer olympics – men 200 metre individual medley men 200 metre individual medley event 2004 olympic game contested olympic aquatic centre athens olympic sport complex athens greece august 18 19 u swimmer michael phelps blasted olympic record 15714 claim fourth career gold medal swimming coming fifth place final turn phelps teammate ryan lochte powered home silver 15878 meanwhile george bovell held hungary lászló cseh four hundredth second 004 give trinidad tobago first ever swimming medal commonwealth record 15880 earlier semifinal phelps posted new olympic record 15852 previously set italian swimmer defending olympic champion massimiliano rosolino sydney four year earlier rosolino along teammate alessio boggiatto failed reach top 8 final tenth eleventhplace effort tunisia oussama mellouli placed fifth 400 individual medley also missed cut set african record 20111\n",
      "Document ID: 15, Relevance Score: 0.0, Content: cucujiformia cucujiformia infraorder polyphagan beetle representing vast majority planteating beetle infraorder contains six superfamily chrysomeloidea 7 family including longhorn beetle leaf beetle cleroidea checkered beetle barkgnawing beetle softwinged flower beetle cucujoidea 32 family includes ladybird fungus beetle curculionoidea 8 family primarily consisting weevil also including snout beetle bark beetle lymexyloidea shiptimber beetle tenebrionoidea formerly heteromera 30 family including blister beetle antlike beetle\n",
      "Document ID: 16, Relevance Score: 0.0, Content: 6l6 6l6 designator vacuum tube introduced radio corporation america july 1936 time philip already developed patented power pentode design fast replacing power triode due greater efficiency beam tetrode design 6l6 allowed rca circumvent philip pentode patent\n",
      "Document ID: 17, Relevance Score: 0.0, Content: bush mountain geographical feature include anderson height kosco glacier mcintyre promontory mincey glacier mount boyd mount cromie ramsey glacier\n",
      "Document ID: 18, Relevance Score: 0.0, Content: gaudete sunday laetare sunday advent sunday gaudete christmas carol\n",
      "Document ID: 19, Relevance Score: 0.0, Content: shiny entertainment formation 1991 video game developer david perry working probe software london movie license based video game terminator mega drivegenesis game published virgin game irvine california proposal made perry agreed complete work united state moved join virgin game usa development team state developed mcdonalds global gladiator 7ups cool spot early development work disney jungle book worked disney aladdin joint venture virgin game usa sega america commercial successful time perry got u green card formed new company fund signed threegame distribution deal playmate interactive entertainment shiny entertainment inc formed october 1993 company first release earthworm jim sega mega drivegenesis commercially successful sega game year award several merchandising deal followed resulted earthworm jim tv show comic book toy line product game later ported platform sequel titled earthworm jim 2 followed 1995 year company acquired interplay entertainment half original eightman team including perry righthand man doug tennapel left form gaming company neverhood inc sega nintendo also made offer acquire shiny entertainment turned according perry weve always wanted cover whole gaming field 1997 former shiny employee nick bruty president bob stevenson ceo left form company planet moon studio two earthworm jim game shiny created mdk 3d action game one precursor third person shooter genre would released 1997 pc ported several platform 1998 interplay copublished mdk playmate interactive entertainment 2000 shiny entertainment released two game two different genre 3d action game messiah 3d realtime strategy game sacrifice neither became successful shinys previous release messiah perceived professional reviewer rushed release technical problem flawed gameplay sacrifice well received critic still become commercial success acquisition infogrames 2002 interplay sold shiny infogrames inc 47 million along current project enter matrix despite poor critical reception enter matrix became commercial success shiny created another game based license matrix path neo released 2005 critical reception mediocre become commercially successful previous game perry launched new earthworm jim game sonys playstation portable well new fighting game called age element e3 2006 none ever finished atari inc announced interest selling development studio perry resigned october 2 2006 foundation 9 entertainment acquired shiny entertainment october 2007 foundation 9 merged shiny entertainment collective form double helix game\n",
      "Document ID: 20, Relevance Score: 0.0, Content: daniel j callaghan may 1941 early stage world war ii roosevelt released callaghan take command cruiser us san francisco ca38 roosevelt wrote great regret letting captain callaghan leave naval aide given every satisfaction performed duty many variety tact real efficiency shown real understanding many problem service within relationship rest government april 1942 promoted rank rear admiral appointed chief staff commander south pacific area south pacific force vice admiral robert l ghormley november commander task group 674 led u force engagement savo island guadalcanal campaign battle bridge us san francisco incoming enemy fire killed command staff november 13 1942 time became third u navy admiral killed action world war ii received medal honor posthumously effort battle following explosion lieutenant commander bruce mccandless assumed operational command san francisco earlier battle rear admiral norman scott killed two u commander lost well several staff despite death many senior officer battle ended strategic victory allied side hindsight callaghan criticized putting five ship superior sg radar system end column using one flagship directing battle flagship bridge instead radar plot issuing battle plan captain issuing confusing order battle analysis battle led rapid improvement usn technique fighting poor visibility particularly adoption combat information center callaghan buried sea survived wife mary tormey callaghan son daniel judson callaghan jr 1915–2006 brother william callaghan would later become u navy vice admiral first captain first commander military sea transportation service order president roosevelt rear admiral callaghan scott posthumously awarded navy medal honor\n",
      "Document ID: 21, Relevance Score: 0.0, Content: toowong \n",
      "Document ID: 22, Relevance Score: 0.0, Content: epilasik epilasik refractive surgery technique designed reduce person dependency eyeglass contact lens invented dr ioannis pallikaris crete greece technique basically automatic lasek without alcohol better considered superficial lasik stromal bed smoother obtained mechanical method brush unlike alcohol lasek chance damaging limbal stem cell also relatively le painful lasek device similar microkeratome called epikeratome slide surface cornea underneath epithelial layer cell suction applied result hinged sheet epithelium least partially viable reflected way ablation take place sheet repositioned bandage soft contact lens placed eye recent study show surface epithelial layer cornea heals faster epithelial sheet removed end surgery mean original rationale carefully cleaving epithelium aim replacing end surgery flawed better fact discard epithelial layer end surgery thus making epilasik different traditional photorefractive keratectomy surgery advantage le damage corneal nerve hence safer dry eye cornea abnormal lasik epilasik may still option first case outside greece performed 2003 september 2003 marguerite mcdonald became first person north america perform epilasik\n",
      "Document ID: 23, Relevance Score: 0.0, Content: kent bank kent bank lie morecambe bay river kent used run sea wall railway since 1993 kent moved towards arnside sand become overgrown shore kent bank village built hill form part hampsfield fell kent bank built forest covering area cut boundary boundary east furness line railway morecambe bay north carter road south kentsford road west b5277 allithwaite road kent bank grangeoversands two separate settlement however two begun merge one kent bank area location climate\n",
      "Document ID: 24, Relevance Score: 0.0, Content: eumycetoma diagnosis mycetoma usually established clinically endemic area x ray ultrasonography may employed evaluating extent disease x ray finding extremely variable disease often observed advanced stage exhibit extensive destruction bone foot rarely single lesion may seen tibia picture identical chronic osteomyelitis cytology fine needle aspirate pu lesion tissue biopsy may undertaken sometimes publication claimed dot circle sign characteristic mri feature condition feature also described ultrasound madura foot xray differential diagnosis following clinical condition may considered diagnosing patient mycetoma tuberculous ulcer kaposis sarcoma vascular tumour skin usually seen aid leprosy syphilis malignant neoplasm tropical ulcer botryomycosis skin infection usually caused bacteria staphylococcus aureus\n",
      "Document ID: 25, Relevance Score: 0.0, Content: heidelberg tun anton praetorius poem 1 great wine barrel castle heidelberg picture literature german\n",
      "Document ID: 26, Relevance Score: 0.0, Content: ferry hong kong ferry hong kong 1959 british melodramaadventure film directed lewis gilbert starring curt jürgens sylvia syms orson welles jeremy spenser\n",
      "Document ID: 27, Relevance Score: 0.0, Content: barral baux barral came oppose albigensian crusade invaded comtat venaissin 1234 support raymond vii toulouse 1239 barral entered negotiation daughter cecile marry guigues vii dauphin viennois another supporter toulouse pressure philip savoy barral reneged engagement saying agreed fear life 1244 barral helped arbitrate latest conflict savoy provence one side dauphin aymar iii valentinois december year cecile married count savoy firmly pulling baux savoy alliance 1246 barral joined soninlaw family bringing army rescue beatrice savoy daughter beatrice provence recently inherited county provence besieged others seeking marry family able safely escort wedding countess new husband respect father toward rest family barral joined provençal rebellion charles anjou 1247 supporting soninlaws family right forced surrender charles june 1251 became supporter charles october helped suppress rebellion 1262 1255 barral called mediate dispute philip savoy valentinoisviennois alliance support charles made grand justiciar sicily died 1268 succeeded lord baux son bertran\n",
      "Document ID: 28, Relevance Score: 0.0, Content: fall river fc second fall river fc played fall 1932 american soccer league season exact origin team unclear new bedford whaler successor team earlier fall river fc fall river marksman also began fall 1932 season survived six game folding however one former player billy gonsalves finished season new fall river club scoring 7 goal 12 game helped win league title\n",
      "Document ID: 29, Relevance Score: 0.0, Content: renoly santiago renoly santiago born lajas puerto rico raised union city new jersey\n",
      "Document ID: 30, Relevance Score: 0.0, Content: edward small source balio tino united artist company built star volume 1 1919–1950 university wisconsin press 2009\n",
      "Document ID: 31, Relevance Score: 0.0, Content: chetan bhagat list indian writer\n",
      "Document ID: 32, Relevance Score: 0.0, Content: coordinated incident management system cim using organisation cim used emergency service government agency management agency including agency involved 20122014 review ambulance new zealand st john new zealand wellington free ambulance civil defence emergency management group 16 member local authority collectively represented department conservation department prime minister cabinet maritime new zealand ministry primary industry ministry civil defence emergency management ministry health ministry social development national rural fire authority new zealand custom service new zealand defence force new zealand fire service new zealand police ministry business innovation employment participated 2013 purpose developing underground mine emergency protocol wider adoption business continuitycrisis management recent year cim also recognised best practice implementing management structure response recovery many organisation outside identified adopting cim including lifeline utility university business key benefit adopting recognised standard able interoperate agency response complex event involve one agency land search rescue new zealand land search rescue inc landsar widely adopted use cim\n",
      "Document ID: 33, Relevance Score: 0.0, Content: darren boyko darren boyko born january 16 1964 winnipeg manitoba nhl onegamer elitserien onegamer played one game nhl winnipeg jet 1989 one game elitserien västra frölunda hc 1997 notable numerous year hifk 2006 became second nonfinnish player carl brewer inducted finnish hockey hall fame\n",
      "Document ID: 34, Relevance Score: 0.0, Content: state pension united kingdom married woman young child carers claim credit ni contribution pensioner low income claim pension credit\n",
      "Document ID: 35, Relevance Score: 0.0, Content: seynod \n",
      "Document ID: 36, Relevance Score: 0.0, Content: daniel nash daniel nash 1763 – june 4 1837 episcopal priest missionary native american european settler frontier central new york nash born great barrington massachusetts graduated yale university connecticut became teacher studied ordination episcopal priest moved new lebanon new york 1790s taught school became lay leader church met wife missionary partnertobe olive lusk nash ordained october 11 1801 nash including child move newly settled region western otsego county new york held service small settlement richfield exeter morris father nash performed preaching olive led singing response also preached member oneida tribe 1804 1816 performed 496 baptism organized 12 parish area 1800 nash presided funeral hannah cooper sister james fenimore cooper also first rector christ church cooperstown another daniel nash presbyterian minister early 1800s known today labored prayer second great awakening relation ministry evangelist charles g finney born abington mass nov 27th 1775 died december 20th 1831 verona new york\n",
      "Document ID: 37, Relevance Score: 0.0, Content: optin email optin email term used someone given option receive email typically sort mailing list newsletter advertising without obtaining permission sending email email unsolicited bulk email better known spam\n",
      "Document ID: 38, Relevance Score: 0.0, Content: 1981 tour de france \n",
      "Document ID: 39, Relevance Score: 0.0, Content: naval rank insignia cuba commander chief general army allforces high rank unique feature navy use three lieutenant rank frigate corvette shipoftheline use ensign rank naval rank name shoulder insignia admiral almirante vice admiral vicealmirante rear admiralcounter admiral contralmirante captainshipoftheline captain capitán de navío commandercorvette captain capitán de fragata lieutenant commanderfrigate captain capitán de corbeta lieutenantshipoftheline lieutenant teniente de navío lieutenant junior gradefrigate lieutenant teniente de fragata probationary lieutenantcorvette lieutenant teniente de corbeta ensign alférez\n",
      "Document ID: 40, Relevance Score: 0.0, Content: music magazine 1975 derek bailey steve beresford max boucher paul burwell jack cooke peter cusack hugh davy madelaine martin davidson richard leigh evan parker john russell david toop philipp wachsmann colin wood came together agreed produce magazine would independent dedicated mainly coverage free improvised music need originally suggested conversation evan parker madelaine martin davidson title proposed paul burwell first meeting davidsons house unanimously adopted title represented paradigm shift music headquartered london published since 1979\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from math import log, sqrt\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def clean_and_preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase the text\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    stop_words = set(stopwords.words('english'))  # Get English stopwords\n",
    "    lemmatizer = WordNetLemmatizer()  # Initialize lemmatizer\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]  # Lemmatize and remove stopwords\n",
    "    cleaned_text = ' '.join(tokens)  # Join tokens back into text\n",
    "    return cleaned_text\n",
    "\n",
    "# Read the CSV file and clean data\n",
    "df = pd.read_csv(\"sampled.csv\")\n",
    "df['TITLE'] = df['TITLE'].apply(clean_and_preprocess_text)\n",
    "df['SECTION_TEXT'] = df['SECTION_TEXT'].apply(clean_and_preprocess_text)\n",
    "df['ARTICLE_TEXT'] = df['TITLE'] + \" \" + df['SECTION_TEXT']\n",
    "\n",
    "# Preprocessing\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Function to calculate term frequency\n",
    "def calculate_term_frequency(text):\n",
    "    word_counts = Counter(text.split())\n",
    "    return word_counts\n",
    "\n",
    "# Calculate term frequency for each document\n",
    "df_cleaned['TERM_FREQUENCY'] = df_cleaned['ARTICLE_TEXT'].apply(calculate_term_frequency)\n",
    "\n",
    "# Function to calculate document frequency\n",
    "def calculate_document_frequency(df):\n",
    "    document_frequency = Counter()\n",
    "    for index, row in df.iterrows():\n",
    "        document_frequency.update(row['TERM_FREQUENCY'].keys())\n",
    "    return document_frequency\n",
    "\n",
    "# Calculate document frequency\n",
    "document_frequency = calculate_document_frequency(df_cleaned)\n",
    "\n",
    "# Function to calculate inverse document frequency\n",
    "def calculate_inverse_document_frequency(total_documents, df):\n",
    "    inverse_document_frequency = {}\n",
    "    for term, freq in df.items():\n",
    "        idf = log(total_documents / (freq + 1))  # Add 1 to avoid division by zero\n",
    "        inverse_document_frequency[term] = idf\n",
    "    return inverse_document_frequency\n",
    "\n",
    "# Calculate total number of documents\n",
    "total_documents = len(df_cleaned)\n",
    "# Calculate inverse document frequency\n",
    "inverse_document_frequency = calculate_inverse_document_frequency(total_documents, document_frequency)\n",
    "\n",
    "# Indexing Engine\n",
    "class IndexingEngine:\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "    \n",
    "    def break_down_documents(self):\n",
    "        words = []\n",
    "        for doc in self.documents:\n",
    "            words.extend(doc.split())\n",
    "        return words\n",
    "\n",
    "    def create_word_ids(self):\n",
    "        words = self.break_down_documents()\n",
    "        unique_words = list(set(words))\n",
    "        word_ids = {word: idx for idx, word in enumerate(unique_words)}\n",
    "        return word_ids\n",
    "\n",
    "    def create_vocabulary(self):\n",
    "        words = self.break_down_documents()\n",
    "        vocabulary = list(set(words))\n",
    "        return vocabulary\n",
    "\n",
    "    def count_word_frequency(self):\n",
    "        word_frequency = {}\n",
    "        for doc_id, doc in enumerate(self.documents):\n",
    "            word_frequency[doc_id] = Counter(doc.split())\n",
    "        return word_frequency\n",
    "\n",
    "indexing_engine = IndexingEngine(df_cleaned['ARTICLE_TEXT'])\n",
    "\n",
    "# Break Down Documents\n",
    "words = indexing_engine.break_down_documents()\n",
    "\n",
    "# Create Word IDs\n",
    "word_ids = indexing_engine.create_word_ids()\n",
    "\n",
    "# Create Vocabulary\n",
    "vocabulary = indexing_engine.create_vocabulary()\n",
    "\n",
    "# Count Word Frequency\n",
    "word_frequency = indexing_engine.count_word_frequency()\n",
    "\n",
    "# User Submits Query\n",
    "query = input(\"Enter your query: \")\n",
    "\n",
    "# Query Vectorizer\n",
    "class QueryVectorizer:\n",
    "    def __init__(self, query, word_ids):\n",
    "        self.query = query\n",
    "        self.word_ids = word_ids\n",
    "\n",
    "    def vectorize_query(self):\n",
    "        query_vector = [0] * len(self.word_ids)\n",
    "        words = self.query.split()\n",
    "        for word in words:\n",
    "            if word in self.word_ids:\n",
    "                idx = self.word_ids[word]\n",
    "                query_vector[idx] += 1\n",
    "        return query_vector\n",
    "\n",
    "query_vectorizer = QueryVectorizer(query, word_ids)\n",
    "vectorized_query = query_vectorizer.vectorize_query()\n",
    "\n",
    "# Ranker Engine\n",
    "class RankerEngine:\n",
    "    def __init__(self, vectorized_query, term_frequency, inverse_document_frequency):\n",
    "        self.vectorized_query = vectorized_query\n",
    "        self.term_frequency = term_frequency\n",
    "        self.inverse_document_frequency = inverse_document_frequency\n",
    "        self.scores = self.calculate_scores()\n",
    "    \n",
    "    def calculate_scores(self):\n",
    "        scores = {}\n",
    "        for doc_id, doc in self.term_frequency.items():\n",
    "            score = 0\n",
    "            doc_length = sum(doc.values())\n",
    "            for word_id, query_weight in enumerate(self.vectorized_query):\n",
    "                if word_id in doc:\n",
    "                    doc_weight = doc[word_id]\n",
    "                    score += (query_weight * doc_weight / doc_length) * self.inverse_document_frequency[word_id]\n",
    "            scores[doc_id] = score / sqrt(sum(map(lambda x: x*x, self.vectorized_query)))  # Normalize by query length\n",
    "        return scores\n",
    "\n",
    "ranker_engine = RankerEngine(vectorized_query, word_frequency, inverse_document_frequency)\n",
    "document_scores = ranker_engine.scores\n",
    "\n",
    "# Display document scores\n",
    "for doc_id, score in document_scores.items():\n",
    "    print(f\"Document ID: {doc_id}, Relevance Score: {score}, Content: {df_cleaned.iloc[doc_id]['ARTICLE_TEXT']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Documents:\n",
      "Document ID: 0\n",
      "Document ID: 1\n",
      "Document ID: 2\n",
      "Document ID: 3\n",
      "Document ID: 4\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# Step 1: Data Cleaning\n",
    "def clean_text(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Step 2: Word Counting\n",
    "def count_words(documents):\n",
    "    word_counts = defaultdict(int)\n",
    "    for document in documents:\n",
    "        words = document.split()\n",
    "        for word in words:\n",
    "            word_counts[word] += 1\n",
    "    return word_counts\n",
    "\n",
    "# Step 3: Word Indexing\n",
    "def create_word_index(word_counts):\n",
    "    word_index = {}\n",
    "    index = 0\n",
    "    for word, count in word_counts.items():\n",
    "        word_index[word] = {'id': index, 'count': count}\n",
    "        index += 1\n",
    "    return word_index\n",
    "\n",
    "# Step 4: Vocabulary Creation\n",
    "def create_vocabulary(word_index):\n",
    "    vocabulary = list(word_index.keys())\n",
    "    return vocabulary\n",
    "\n",
    "# Step 5: Normalization\n",
    "def normalize_word_counts(word_counts):\n",
    "    total_count = sum(word_counts.values())\n",
    "    normalized_counts = {word: count / total_count for word, count in word_counts.items()}\n",
    "    return normalized_counts\n",
    "\n",
    "# Step 6: Query Handling\n",
    "def process_query(query, word_index):\n",
    "    query_vector = defaultdict(int)\n",
    "    query_words = query.split()\n",
    "    for word in query_words:\n",
    "        if word in word_index:\n",
    "            query_vector[word] += 1\n",
    "    return query_vector\n",
    "\n",
    "# Step 7: Query Vectorization (Simple Bag-of-Words Model)\n",
    "def vectorize_query(query, vocabulary):\n",
    "    query_vector = [0] * len(vocabulary)\n",
    "    query_words = query.split()\n",
    "    for word in query_words:\n",
    "        if word in vocabulary:\n",
    "            index = vocabulary.index(word)\n",
    "            query_vector[index] += 1\n",
    "    return query_vector\n",
    "\n",
    "# Load and process data from sampled.csv\n",
    "def process_data(filename):\n",
    "    cleaned_documents = []\n",
    "    document_ids = []\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for i, row in enumerate(reader):\n",
    "            cleaned_doc = clean_text(row[0])\n",
    "            cleaned_documents.append(cleaned_doc)\n",
    "            document_ids.append(i)  # Assigning a unique ID to each document\n",
    "    return cleaned_documents, document_ids\n",
    "\n",
    "def rank_documents(query_vector_bow, document_vectors):\n",
    "    # Compute cosine similarity between query vector and document vectors\n",
    "    similarities = []\n",
    "    for doc_vector in document_vectors:\n",
    "        dot_product = sum(a * b for a, b in zip(query_vector_bow, doc_vector))\n",
    "        query_norm = math.sqrt(sum(a**2 for a in query_vector_bow))\n",
    "        doc_norm = math.sqrt(sum(a**2 for a in doc_vector))\n",
    "        \n",
    "        # Check for zero magnitude vectors to avoid division by zero\n",
    "        if query_norm == 0 or doc_norm == 0:\n",
    "            similarity = 0  # Assign zero similarity\n",
    "        else:\n",
    "            similarity = dot_product / (query_norm * doc_norm)\n",
    "        \n",
    "        similarities.append(similarity)\n",
    "    \n",
    "    # Sort document IDs based on similarity scores\n",
    "    ranked_document_ids = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)\n",
    "    return ranked_document_ids\n",
    "\n",
    "# Document Identification\n",
    "def identify_documents(document_ids, ranked_document_ids, top_k=5):\n",
    "    # Return top k documents based on ranking\n",
    "    top_documents = [document_ids[i] for i in ranked_document_ids[:top_k]]\n",
    "    return top_documents\n",
    "\n",
    "# User Response\n",
    "def provide_user_response(top_documents):\n",
    "    print(\"\\nTop Documents:\")\n",
    "    for doc_id in top_documents:\n",
    "        print(f\"Document ID: {doc_id}\")\n",
    "\n",
    "# Main function to execute steps sequentially\n",
    "def main():\n",
    "    # Process data\n",
    "    documents, document_ids = process_data('sampled.csv')\n",
    "    \n",
    "    # Step 2: Word Counting\n",
    "    word_counts = count_words(documents)\n",
    "    \n",
    "    # Step 3: Word Indexing\n",
    "    word_index = create_word_index(word_counts)\n",
    "    \n",
    "    # Step 4: Vocabulary Creation\n",
    "    vocabulary = create_vocabulary(word_index)\n",
    "    \n",
    "    # Step 5: Normalization\n",
    "    normalized_counts = normalize_word_counts(word_counts)\n",
    "    \n",
    "    # Get user query\n",
    "    query = input(\"Enter your query: \")\n",
    "    \n",
    "    # Step 6: Query Handling\n",
    "    query_vector = process_query(query, word_index)\n",
    "    \n",
    "    # Step 7: Query Vectorization\n",
    "    query_vector_bow = vectorize_query(query, vocabulary)\n",
    "    \n",
    "    # Document Vectorization\n",
    "    document_vectors = [vectorize_query(doc, vocabulary) for doc in documents]\n",
    "    \n",
    "    # Document Ranking\n",
    "    ranked_document_ids = rank_documents(query_vector_bow, document_vectors)\n",
    "    \n",
    "    # Document Identification\n",
    "    top_documents = identify_documents(document_ids, ranked_document_ids)\n",
    "    \n",
    "    # User Response\n",
    "    provide_user_response(top_documents)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
